{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import chardet\n",
    "\n",
    "# # 检测文件编码\n",
    "# with open('./DataSet/Tokyo_20131_20234.csv', 'rb') as f:\n",
    "#     result = chardet.detect(f.read())\n",
    "#     encoding = result['encoding']\n",
    "#     print(f\"Detected encoding: {encoding}\")\n",
    "\n",
    "# 使用检测到的编码读取文件\n",
    "df = pd.read_csv('../DataSet/Tokyo house price.csv', encoding=\"cp932\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 列名列表\n",
    "columns = ['種類', '価格情報区分', '地域', '市区町村コード', '都道府県名', '市区町村名', '地区名', '最寄駅：名称','最寄駅：距離（分）', '取引価格（総額）', '坪単価', '面積（㎡）', '取引価格（㎡単価）', '土地の形状', '間口','延床面積（㎡）', '建築年', '建物の構造', '用途', '今後の利用目的', '前面道路：方位', '前面道路：種類','前面道路：幅員（ｍ）', '都市計画', '建ぺい率（％）', '容積率（％）', '取引時期', '取引の事情等']\n",
    "\n",
    "# 打印每一列的唯一值和唯一值的数量\n",
    "for column in columns:\n",
    "    unique_values = df[column].unique()\n",
    "    unique_count = df[column].nunique()\n",
    "    print(f\"{column}: 有 {unique_count} 个唯一值。\")\n",
    "    print(f\"这些唯一值是: {unique_values}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 筛选出'取引時期'列中包含2018年至2023年的数据\n",
    "df['取引時期'] = df['取引時期'].astype(str)\n",
    "filtered_df = df[df['取引時期'].str.contains(r'202[0-3]|201[8-9]', regex=True)]\n",
    "filtered_df = filtered_df .query('種類 == \"宅地(土地と建物)\"')\n",
    "filtered_df = filtered_df .query('種類 == \"宅地(土地と建物)\"')\n",
    "filtered_df = filtered_df .query('今後の利用目的 == \"住宅\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns = ['最寄駅：距離（分）', '取引価格（総額）', '面積（㎡）','建築年', '建物の構造','地区名',\"建ぺい率（％）\",\"容積率（％）\"]\n",
    "selected_df = df[selected_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_df = selected_df.dropna()\n",
    "#astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 提取建筑年份的年份部分并转换为整数\n",
    "selected_df['建築年'] = selected_df['建築年'].str.extract('(\\d+)')\n",
    "selected_df = selected_df.dropna()\n",
    "selected_df['建築年'] = selected_df['建築年'].astype(int)\n",
    "# selected_df['建築年'] = selected_df['建築年'].astype(int)\n",
    "# selected_df['建筑年限'] = 2024 - selected_df['建築年']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_df.to_csv('exported_data3.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "# 使用OneHotEncoder进行独热编码\n",
    "one_hot_encoder = OneHotEncoder(sparse=False)\n",
    "encoded_features = one_hot_encoder.fit_transform(selected_df[['地区名']])\n",
    "\n",
    "# 获取独热编码后的特征名\n",
    "feature_names = one_hot_encoder.get_feature_names_out(['地区名'])\n",
    "\n",
    "# 将编码后的特征转换为DataFrame\n",
    "encoded_df = pd.DataFrame(encoded_features, columns=feature_names)\n",
    "\n",
    "# 合并原始数据和独热编码后的数据\n",
    "df_onehot = pd.concat([selected_df, encoded_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#使用encoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# 确保列为字符串类型\n",
    "for column in [ '建物の構造','地区名']:\n",
    "    selected_df[column] = selected_df[column].astype(str)\n",
    "\n",
    "# 创建LabelEncoder对象\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# 对每个object列进行标签编码\n",
    "for column in [ '建物の構造','地区名']:\n",
    "    selected_df[column] = label_encoder.fit_transform(selected_df[column])\n",
    "\n",
    "print(selected_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_df['最寄駅：距離（分）'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义映射关系\n",
    "distance_mapping = {\n",
    "    '30分～60分': 30,\n",
    "    '1H～1H30': 60,\n",
    "    '1H30～2H': 90,\n",
    "    '2H～': 120,\n",
    "    '2,000㎡以上': 120\n",
    "}\n",
    "\n",
    "# 将文本值映射成数字\n",
    "selected_df['最寄駅：距離（分）'] = selected_df['最寄駅：距離（分）'].map(lambda x: distance_mapping[x] if x in distance_mapping else int(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义映射关系\n",
    "distance_mapping = {\n",
    "    '2,000㎡以上': 2000\n",
    "}\n",
    "\n",
    "# 将文本值映射成数字\n",
    "selected_df['面積（㎡）'] = selected_df['面積（㎡）'].map(lambda x: distance_mapping[x] if x in distance_mapping else int(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_df['面積（㎡）'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义一个函数来去除离群值\n",
    "# 四分位距（IQR）方法是一种常用的检测离群值的方法。它利用数据的第一四分位数（Q1）和第三四分位数（Q3）来定义一个范围，任何超出该范围的值都被视为离群值。\n",
    "def remove_outliers(df, column):\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    df_filtered = df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]\n",
    "    return df_filtered\n",
    "\n",
    "# 去除 '取引価格（総額）' 的离群值\n",
    "data_cleaned = remove_outliers(selected_df, '取引価格（総額）')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# 定义一个函数来去除离群值\n",
    "# Z-Score 方法是通过计算每个数据点与均值的标准差来检测离群值的。通常，Z-Score 大于 3 或小于 -3 的数据点被视为离群值。\n",
    "def remove_outliers_zscore(df, column):\n",
    "    mean = df[column].mean()\n",
    "    std = df[column].std()\n",
    "    z_scores = (df[column] - mean) / std\n",
    "    df_filtered = df[np.abs(z_scores) < 3]\n",
    "    return df_filtered\n",
    "\n",
    "# 去除 '取引価格（総額）' 的离群值\n",
    "data_cleaned = remove_outliers_zscore(data_cleaned, '取引価格（総額）')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义一个函数来去除离群值\n",
    "# Z-Score 方法是通过计算每个数据点与均值的标准差来检测离群值的。通常，Z-Score 大于 3 或小于 -3 的数据点被视为离群值。\n",
    "def remove_outliers_zscore(df, column):\n",
    "    mean = df[column].mean()\n",
    "    std = df[column].std()\n",
    "    z_scores = (df[column] - mean) / std\n",
    "    df_filtered = df[np.abs(z_scores) < 3]\n",
    "    return df_filtered\n",
    "\n",
    "# 去除 '取引価格（総額）' 的离群值\n",
    "data_cleaned = remove_outliers_zscore(data_cleaned, '面積（㎡）')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义一个函数来去除离群值\n",
    "# 四分位距（IQR）方法是一种常用的检测离群值的方法。它利用数据的第一四分位数（Q1）和第三四分位数（Q3）来定义一个范围，任何超出该范围的值都被视为离群值。\n",
    "def remove_outliers(df, column):\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    df_filtered = df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]\n",
    "    return df_filtered\n",
    "\n",
    "# 去除 '取引価格（総額）' 的离群值\n",
    "data_cleaned = remove_outliers(selected_df, '面積（㎡）')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义一个函数来去除离群值\n",
    "# 四分位距（IQR）方法是一种常用的检测离群值的方法。它利用数据的第一四分位数（Q1）和第三四分位数（Q3）来定义一个范围，任何超出该范围的值都被视为离群值。\n",
    "def remove_outliers(df, column):\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    df_filtered = df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]\n",
    "    return df_filtered\n",
    "\n",
    "# 去除 '取引価格（総額）' 的离群值\n",
    "data_cleaned = remove_outliers(selected_df, '建築年')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cleaned = data_cleaned[data_cleaned['取引価格（総額）'] <= 100000000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cleaned = data_cleaned[data_cleaned['建築年'] > 1968]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cleaned = data_cleaned[data_cleaned['面積（㎡）'] < 200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cleaned = data_cleaned[data_cleaned['最寄駅：距離（分）'] < 30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cleaned.to_csv('exported_data5.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3428/3428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 9ms/step - loss: 1.0568 - r2_score: -39.1756 - val_loss: 0.7647 - val_r2_score: -34.6842\n",
      "Epoch 2/50\n",
      "\u001b[1m3428/3428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 9ms/step - loss: 0.8072 - r2_score: -39.4750 - val_loss: 0.7177 - val_r2_score: -35.6996\n",
      "Epoch 3/50\n",
      "\u001b[1m1646/3428\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m15s\u001b[0m 9ms/step - loss: 0.7611 - r2_score: -40.3189"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import TensorBoard, EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from datetime import datetime\n",
    "import os\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "data_cleaned = pd.read_csv(\"./exported_data5.csv\")\n",
    "X = data_cleaned.drop('取引価格（総額）', axis=1)\n",
    "y = data_cleaned['取引価格（総額）']\n",
    "\n",
    "# 数据标准化处理\n",
    "scaler_X = StandardScaler()\n",
    "X_scaled = scaler_X.fit_transform(X)\n",
    "\n",
    "scaler_y = StandardScaler()\n",
    "y_scaled = scaler_y.fit_transform(y.values.reshape(-1, 1)).flatten()\n",
    "\n",
    "# 将数据划分为训练集和验证集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_scaled, test_size=0.2, random_state=42)\n",
    "\n",
    "# 创建 Sequential 模型\n",
    "model = Sequential()\n",
    "\n",
    "\n",
    "# 添加输入层和隐藏层\n",
    "model.add(Dense(128, input_dim=X_train.shape[1], activation='relu'))\n",
    "model.add(Dropout(0.5))  # 添加 dropout 防止过拟合\n",
    "# 添加输入层和隐藏层\n",
    "model.add(Dense(64, input_dim=X_train.shape[1], activation='relu'))\n",
    "model.add(Dropout(0.5))  # 添加 dropout 防止过拟合\n",
    "\n",
    "# 添加更多隐藏层\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# 添加输出层，输出层不需要激活函数（默认是线性输出）\n",
    "model.add(Dense(1, activation='linear'))  # 输出层只有一个神经元，用于预测\n",
    "\n",
    "optimizer = Adam(learning_rate=0.0001)\n",
    "\n",
    "# 自定义 R² 评估函数\n",
    "def r2_score(y_true, y_pred):\n",
    "    ss_res = K.sum(K.square(y_true - y_pred)) \n",
    "    ss_tot = K.sum(K.square(y_true - K.mean(y_true))) \n",
    "    return 1 - ss_res / (ss_tot + K.epsilon())\n",
    "\n",
    "# 编译模型，使用 MSE 损失函数\n",
    "model.compile(loss='mean_squared_error', optimizer=optimizer, metrics=[r2_score])\n",
    "\n",
    "# 生成当前时间的字符串\n",
    "current_time = datetime.now().strftime(\"%Y%m%d-%H%M\")\n",
    "\n",
    "# 创建日志目录名称\n",
    "log_dir = os.path.join('logs', current_time)\n",
    "\n",
    "# TensorBoard 回调函数\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# 训练模型batch_size=32,\n",
    "history = model.fit(X_train, y_train, epochs=50, validation_data=(X_test, y_test), callbacks=[tensorboard_callback, early_stopping_callback])\n",
    "\n",
    "# 模型评估\n",
    "mse = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f'Validation MSE: {mse:.4f}')\n",
    "\n",
    "# 预测验证集\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# 反标准化预测结果\n",
    "y_pred_original = scaler_y.inverse_transform(y_pred.flatten().reshape(-1, 1)).flatten()\n",
    "y_val_original = scaler_y.inverse_transform(y_test.reshape(-1, 1)).flatten()\n",
    "\n",
    "# 计算评价指标\n",
    "mse = mean_squared_error(y_val_original, y_pred_original)\n",
    "mae = mean_absolute_error(y_val_original, y_pred_original)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_val_original, y_pred_original)\n",
    "mape = np.mean(np.abs((y_val_original - y_pred_original) / y_val_original)) * 100\n",
    "\n",
    "print(f'MSE: {mse:.4f}')\n",
    "print(f'MAE: {mae:.4f}')\n",
    "print(f'RMSE: {rmse:.4f}')\n",
    "print(f'R2: {r2:.4f}')\n",
    "print(f'MAPE: {mape:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import TensorBoard, EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from datetime import datetime\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import os\n",
    "data_cleaned = pd.read_csv(\"./exported_data5.csv\")\n",
    "\n",
    "# 将价格转换为类别标签\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(data_cleaned['取引価格（総額）'])\n",
    "\n",
    "# 数据标准化处理\n",
    "X = data_cleaned.drop('取引価格（総額）', axis=1)\n",
    "y = y_encoded\n",
    "\n",
    "scaler_X = StandardScaler()\n",
    "X_scaled = scaler_X.fit_transform(X)\n",
    "\n",
    "# 将数据划分为训练集和验证集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# # 创建 Sequential 模型\n",
    "# model = Sequential()\n",
    "# 构建模型\n",
    "model = Sequential([\n",
    "    Dense(128, input_dim=X_train.shape[1], activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(len(np.unique(y)), activation='softmax')# 添加输出层，使用 softmax 激活函数\n",
    "])\n",
    "\n",
    "# # 添加输入层和隐藏层\n",
    "# model.add(Dense(128, input_dim=X_train.shape[1], activation='relu'))\n",
    "# model.add(Dropout(0.5))  # 添加 dropout 防止过拟合\n",
    "\n",
    "# # 添加更多隐藏层\n",
    "# model.add(Dense(64, activation='relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "\n",
    "\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "\n",
    "# 编译模型，使用交叉熵损失函数\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "# 生成当前时间的字符串\n",
    "current_time = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "# 创建日志目录名称\n",
    "log_dir = os.path.join('logs', current_time)\n",
    "\n",
    "# TensorBoard 回调函数\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# 训练模型\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test), callbacks=[tensorboard_callback, early_stopping_callback])\n",
    "\n",
    "# 模型评估\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f'Validation Loss: {loss:.4f}, Validation Accuracy: {accuracy:.4f}')\n",
    "\n",
    "# 预测验证集\n",
    "y_pred_prob = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "\n",
    "# 计算准确率\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
